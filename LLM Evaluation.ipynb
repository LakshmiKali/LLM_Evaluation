{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lakie\\anaconda3\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: bert-score in c:\\users\\lakie\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (2.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (2.0.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (4.45.1)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (4.64.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (3.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.6.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert-score) (2024.3.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert-score) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from torch>=1.0.0->bert-score) (2.11.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->bert-score) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->bert-score) (1.25.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from requests->bert-score) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2020.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert-score) (5.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.20.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from matplotlib->bert-score) (0.10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from networkx->torch>=1.0.0->bert-score) (4.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.9258, Recall: 0.9258, F1: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9258, 0.9258, 0.9258)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "# Example texts\n",
    "reference = \"This is a reference text example.\"\n",
    "candidate = \"This is a candidate text example.\"\n",
    "# BERTScore calculation\n",
    "def bert_score(reference,candidate):\n",
    "    scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "    P, R, F1 = scorer.score([candidate], [reference])\n",
    "    print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")\n",
    "    \n",
    "    return round(P.item(),4), round(R.item(),4), round(F1.item(),4)\n",
    "\n",
    "\n",
    "bert_score(reference,candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the required libraries\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Load the pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Step 3: Define the two texts to compare\n",
    "text1 = \"This is a reference text example.\"\n",
    "text2 = \"This is a candidate text example.\"\n",
    "\n",
    "# Step 4: Prepare the texts for BERT\n",
    "inputs1 = tokenizer(text1, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Step 5: Feed the texts to the BERT model\n",
    "outputs1 = model(**inputs1)\n",
    "outputs2 = model(**inputs2)\n",
    "\n",
    "# Step 6: Obtain the representation vectors\n",
    "embeddings1 = outputs1.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "embeddings2 = outputs2.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Step 7: Calculate cosine similarity\n",
    "similarity = np.dot(embeddings1, embeddings2.T) / (np.linalg.norm(embeddings1) * np.linalg.norm(embeddings2))\n",
    "\n",
    "# Step 8: Print the result\n",
    "print(\"Similarity between the texts: {:.4f}\".format(similarity[0][0]))\n",
    "\n",
    "### Output: Similarity between the texts: 0.9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lakie\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\lakie\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: The Eiffel Tower is in Paris.\n",
      "Sentence 2: It was built in 1889.\n",
      "Sentence 3: It's one of the most famous landmarks in the world.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lakie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def extract_sentences_nltk(text):\n",
    "    \"\"\"\n",
    "    Function to extract sentences from text using NLTK.\n",
    "    \n",
    "    :param text: String, the text to extract sentences from.\n",
    "    :return: List of sentences.\n",
    "    \"\"\"\n",
    "    # Use NLTK's sent_tokenize to split text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "# Example text\n",
    "text = \"The Eiffel Tower is in Paris. It was built in 1889. It's one of the most famous landmarks in the world.\"\n",
    "\n",
    "# Extract sentences using NLTK\n",
    "sentences = extract_sentences_nltk(text)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "pairs = [ # Test data, List[Tuple[str, str]]. (Input text, summary). (input text, Answer)\n",
    "    (\"The capital of France is Berlin.\", \"The capital of France is Paris.\"), # factual but hallucinated\n",
    "    ('I am in California', 'I am in United States.'), # Consistent\n",
    "    ('I am in United States', 'I am in California.'), # Hallucinated\n",
    "    (\"A person on a horse jumps over a broken down airplane.\", \"A person is outdoors, on a horse.\"),\n",
    "    (\"A boy is jumping on skateboard in the middle of a red bridge.\", \"The boy skates down the sidewalk on a red bridge\"),\n",
    "    (\"A man with blond-hair, and a brown shirt drinking out of a public water fountain.\", \"A blond man wearing a brown shirt is reading a book.\"),\n",
    "    (\"Mark Wahlberg was a fan of Manny.\", \"Manny was a fan of Mark Wahlberg.\")\n",
    "]\n",
    "def hallucination_checker(input):\n",
    "    # Step 1: Load the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "\n",
    "    # Step 2: Use the model to predict\n",
    "    scores = model.predict(input) # note the predict() method. Do not do model(pairs).\n",
    "#     print(scores)\n",
    "    # tensor([0.0111, 0.6474, 0.1290, 0.8969, 0.1846, 0.0050, 0.0543])\n",
    "#     print(input)\n",
    "    for text, score in zip(input, scores):\n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"Hallucination: {'Yes' if score<0.5 else 'No'}, Score: {score:.4f}\")\n",
    "        hallucination_sent = []\n",
    "        if score<0.5:\n",
    "            # Extract sentences using NLTK\n",
    "            sentences = extract_sentences_nltk(text[1])\n",
    "            for sent in sentences:\n",
    "#                 print([(input[0][0],sent)])\n",
    "                score = model.predict([(text[0],sent)])\n",
    "#                 print(score)\n",
    "                if score < 0.5:\n",
    "                    hallucination_sent.append(sent)\n",
    "            print(\"Hallucination sentences \", hallucination_sent,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: ('The capital of France is Berlin.', 'The capital of France is Paris.')\n",
      "Hallucination: Yes, Score: 0.0111\n",
      "Hallucination sentences  ['The capital of France is Paris.'] \n",
      "\n",
      "\n",
      "Text: ('I am in California', 'I am in United States.')\n",
      "Hallucination: No, Score: 0.6474\n",
      "\n",
      "Text: ('I am in United States', 'I am in California.')\n",
      "Hallucination: Yes, Score: 0.1290\n",
      "Hallucination sentences  ['I am in California.'] \n",
      "\n",
      "\n",
      "Text: ('A person on a horse jumps over a broken down airplane.', 'A person is outdoors, on a horse.')\n",
      "Hallucination: No, Score: 0.8969\n",
      "\n",
      "Text: ('A boy is jumping on skateboard in the middle of a red bridge.', 'The boy skates down the sidewalk on a red bridge')\n",
      "Hallucination: Yes, Score: 0.1846\n",
      "Hallucination sentences  ['The boy skates down the sidewalk on a red bridge'] \n",
      "\n",
      "\n",
      "Text: ('A man with blond-hair, and a brown shirt drinking out of a public water fountain.', 'A blond man wearing a brown shirt is reading a book.')\n",
      "Hallucination: Yes, Score: 0.0050\n",
      "Hallucination sentences  ['A blond man wearing a brown shirt is reading a book.'] \n",
      "\n",
      "\n",
      "Text: ('Mark Wahlberg was a fan of Manny.', 'Manny was a fan of Mark Wahlberg.')\n",
      "Hallucination: Yes, Score: 0.0543\n",
      "Hallucination sentences  ['Manny was a fan of Mark Wahlberg.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hallucination_checker(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: (' There are many techniques available to generate extractive summarization to keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. It’s good to understand Cosine similarity to make the best use of the code you are going to see. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Its measures cosine of the angle between vectors. The angle will be 0 if sentences are similar.', 'There are many techniques available to generate extractive summarization. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.')\n",
      "Hallucination: No, Score: 0.9119\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\" There are many techniques available to generate extractive summarization to keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. It’s good to understand Cosine similarity to make the best use of the code you are going to see. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Its measures cosine of the angle between vectors. The angle will be 0 if sentences are similar.\"\"\"\n",
    "summary = \"\"\"There are many techniques available to generate extractive summarization. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.\"\"\"\n",
    "pairs = [(input_text,summary)]\n",
    "hallucination_checker(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: (' There are many techniques available to generate extractive summarization to keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. It’s good to understand Cosine similarity to make the best use of the code you are going to see. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Its measures cosine of the angle between vectors. The angle will be 0 if sentences are similar.', 'I am an Indian. I love India. I live in Bengaluru. There are many techniques available to generate extractive summarization. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.')\n",
      "Hallucination: Yes, Score: 0.1505\n",
      "Hallucination sentences  ['I am an Indian.', 'I love India.', 'I live in Bengaluru.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\" There are many techniques available to generate extractive summarization to keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. It’s good to understand Cosine similarity to make the best use of the code you are going to see. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Its measures cosine of the angle between vectors. The angle will be 0 if sentences are similar.\"\"\"\n",
    "summary = \"\"\"I am an Indian. I love India. I live in Bengaluru. There are many techniques available to generate extractive summarization. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.\"\"\"\n",
    "pairs = [(input_text,summary)]\n",
    "hallucination_checker(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive Summary:\n",
      "The fox told them about the lazy dog. The dog barked back at the fox. It was a peaceful day for the dog, but the fox had a lot to do in the forest. \n",
      "    The quick brown fox jumps over the lazy dog.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lakie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import math\n",
    "\n",
    "# Download required NLTK datasets (only needed once)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 1. Preprocess the text and tokenize it into sentences\n",
    "def preprocess_sentences(text):\n",
    "    sentences = sent_tokenize(text)  # Tokenize the text into sentences\n",
    "    return sentences\n",
    "\n",
    "# 2. Build a similarity matrix for the sentences\n",
    "def build_similarity_matrix(sentences):\n",
    "    # Initialize the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Create a matrix of sentence vectors (TF-IDF weighted)\n",
    "    sentence_vectors = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Compute pairwise cosine similarity between sentence vectors\n",
    "    similarity_matrix = cosine_similarity(sentence_vectors)\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "# 3. Rank the sentences based on their centrality (sum of similarities)\n",
    "def rank_sentences(sentences, similarity_matrix):\n",
    "    # Calculate sentence scores based on the sum of cosine similarities\n",
    "    sentence_scores = similarity_matrix.sum(axis=1)\n",
    "    \n",
    "    # Rank sentences by their scores\n",
    "    ranked_sentences = [(score, sentence) for score, sentence in zip(sentence_scores, sentences)]\n",
    "    ranked_sentences = sorted(ranked_sentences, reverse=True, key=lambda x: x[0])\n",
    "    \n",
    "    return ranked_sentences\n",
    "\n",
    "# 4. Generate the summary by extracting the top-ranked sentences\n",
    "def generate_summary(text, perc = 10):\n",
    "    # Preprocess the text and tokenize into sentences\n",
    "    sentences = preprocess_sentences(text)\n",
    "    sentence_seperation = extract_sentences_nltk(text)\n",
    "#     print(len(sentence_seperation))\n",
    "    num_sentences = math.ceil(len(sentence_seperation)*(perc/100))\n",
    "#     print(num_sentences)\n",
    "    # Build a similarity matrix for the sentences\n",
    "    similarity_matrix = build_similarity_matrix(sentences)\n",
    "    \n",
    "    # Rank the sentences\n",
    "    ranked_sentences = rank_sentences(sentences, similarity_matrix)\n",
    "    \n",
    "    # Extract the top-ranked sentences for the summary\n",
    "    summary_sentences = [ranked_sentences[i][1] for i in range(num_sentences)]\n",
    "    \n",
    "    return ' '.join(summary_sentences)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog. The dog barked back at the fox. The fox ran away into the forest.\n",
    "    In the forest, the fox met other animals. They all wondered what the fox was doing there. The fox told them about the lazy dog.\n",
    "    Meanwhile, the dog went back to sleep. It was a peaceful day for the dog, but the fox had a lot to do in the forest.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary = generate_summary(text, perc=50)\n",
    "    print(\"Extractive Summary:\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supert(input_text,summary):\n",
    "    reference_summary = generate_summary(input_text, perc=10)\n",
    "    bert_score(reference_summary,summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.4808, Recall: 0.5014, F1: 0.4909\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog. The dog barked back at the fox. The fox ran away into the forest.\n",
    "    In the forest, the fox met other animals. They all wondered what the fox was doing there. \n",
    "    The fox told them about the lazy dog.\n",
    "    Meanwhile, the dog went back to sleep. It was a peaceful day for the dog, but the fox had a lot to do in the forest.\n",
    "    \"\"\"\n",
    "summary =\"\"\" Dog had a peaceful day but fox was threatend by dog\"\"\"\n",
    "supert(input_text,summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
